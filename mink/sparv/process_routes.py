"""Routes related to Sparv."""

import time

from fastapi import APIRouter, Depends, Query, status
from fastapi.responses import JSONResponse

from mink.cache import cache_utils
from mink.core import exceptions, info, jobs, models, registry, utils
from mink.core.config import settings
from mink.core.logging import logger
from mink.core.status import JobStatuses, ProcessName, Status
from mink.sb_auth import login
from mink.sparv import models as sparv_models
from mink.sparv import storage

router = APIRouter()


@router.put(
    "/run-sparv",
    tags=["Process Corpus"],
    response_model=sparv_models.StatusResponse,
    responses={
        **models.common_auth_error_responses,
        status.HTTP_400_BAD_REQUEST: {
            "model": models.BaseErrorResponse,
            "content": {
                "application/json": {
                    "example": {
                        "status": "error",
                        "message": "The importer in your config file is incompatible with your source files",
                        "return_code": "incompatible_config_importer",
                        "current_importer": "text_import",
                        "expected_importer": "xml_import",
                    }
                }
            },
        },
        status.HTTP_404_NOT_FOUND: {
            "model": models.ErrorResponse404,
            "content": {
                "application/json": {
                    "example": {
                        "status": "error",
                        "message": "No source files found for 'mink-dxh6e6wtff'",
                        "return_code": "no_sources_found",
                    }
                }
            },
        },
        status.HTTP_500_INTERNAL_SERVER_ERROR: {
            "model": models.ErrorResponse500,
            "content": {
                "application/json": {
                    "example": {
                        "status": "error",
                        "message": "Failed to queue job for 'mink-dxh6e6wtff'",
                        "return_code": "failed_queuing",
                        "info": "BaseException",
                    }
                }
            },
        },
    },
)
async def run_sparv(
    exports: list[str] | None = Query(None, description="Sparv exports to produce"),
    files: list[str] | None = Query(None, description="Source files to process"),
    auth_data: dict = Depends(login.AuthDependency()),
) -> JSONResponse:
    """Add a Sparv annotation job for the corpus to the queue.

    The requested export formats may be supplied as a comma-separated list to the `exports` parameter. If no export
    formats are specified, the `xml_export:pretty` export will be generated by default.

    The `files` parameter can be used to run the pipeline on a part of the corpus. The key to `files` is a
    comma-separated list of file names without file extensions, e.g. `files=dokument1,dokument2`.

    There can only be one active job (annotation or installation) for each corpus at a time. A job must finish or be
    aborted before a new one can be started.

    ### Example

    ```bash
    curl -X PUT '{{host}}/run-sparv?resource_id=some_resource_id&exports=csv_export:csv,stats_export:freq_list,\
xml_export:pretty' -H 'Authorization: Bearer YOUR_JWT'
    ```
    """
    resource_id = auth_data["resource_id"]
    # Parse requested exports
    if exports is None:
        exports = []
    exports = [i.strip() for i in exports if i] or settings.SPARV_DEFAULT_EXPORTS

    # Parse list of files to be processed
    if files is None:
        files = []
    files = [i.strip() for i in files if i]

    # Get list of available source files to be stored in the job info
    try:
        source_files = storage.list_contents(storage.get_source_dir(resource_id))
    except Exception as e:
        raise exceptions.MinkHTTPException(
            status.HTTP_500_INTERNAL_SERVER_ERROR,
            message=f"Failed to list source files in '{resource_id}'",
            return_code="failed_listing_sources",
            info=str(e),
        ) from e

    if not source_files:
        raise exceptions.MinkHTTPException(
            status.HTTP_404_NOT_FOUND,
            message=f"No source files found for '{resource_id}'",
            return_code="no_sources_found",
        )

    # Check compatibility between source files and config
    try:
        config_contents = storage.get_file_contents(storage.get_config_file(resource_id))
    except Exception as e:
        raise exceptions.MinkHTTPException(
            status.HTTP_500_INTERNAL_SERVER_ERROR,
            message=f"Failed to get config file for '{resource_id}'",
            return_code="failed_getting_config",
            info=str(e),
        ) from e
    if source_files:
        compatible, current_importer, expected_importer = utils.config_compatible(config_contents, source_files[0])
        if not compatible:
            raise exceptions.MinkHTTPException(
                status.HTTP_400_BAD_REQUEST,
                message="The importer in your config file is incompatible with your source files",
                return_code="incompatible_config_importer",
                current_importer=current_importer,
                expected_importer=expected_importer,
            )

    # Get info_item, check for changes and remove exports if necessary
    sources_deleted = config_changed = False
    try:
        info_item = registry.get(resource_id)
        _, sources_deleted, config_changed = storage.get_file_changes(resource_id, info_item)
    except exceptions.JobNotFoundError:
        pass
    except Exception as e:
        raise exceptions.MinkHTTPException(
            status.HTTP_500_INTERNAL_SERVER_ERROR,
            message=f"Failed to run job for '{resource_id}'",
            return_code="failed_running",
            info=str(e),
        ) from e
    if sources_deleted or config_changed:
        try:
            success, sparv_output = info_item.job.clean_export()
            assert success
        except Exception as e:
            raise exceptions.MinkHTTPException(
                status.HTTP_500_INTERNAL_SERVER_ERROR,
                message=f"Failed to remove export files from Sparv server for corpus '{resource_id}'. "
                "Cannot run Sparv safely",
                return_code="failed_removing_exports",
                info=str(e),
                sparv_message=sparv_output,
            ) from e

    job = info_item.job
    job.set_sparv_exports(exports)
    job.set_current_files(files)

    # Queue job
    try:
        job = registry.add_to_queue(job)
    except Exception as e:
        raise exceptions.MinkHTTPException(
            status.HTTP_500_INTERNAL_SERVER_ERROR,
            message=f"Failed to queue job for '{resource_id}'",
            return_code="failed_queuing",
            info=str(e),
        ) from e

    # Check that all required files are present
    job.check_requirements()

    if storage.local:
        job.set_status(Status.waiting, ProcessName.sparv)
    else:
        # Sync files
        try:
            job.sync_to_sparv()
        except Exception as e:
            raise exceptions.MinkHTTPException(
                status.HTTP_500_INTERNAL_SERVER_ERROR,
                message=f"Failed to start job for '{resource_id}'",
                return_code="failed_starting_job",
                info=str(e),
            ) from e

    # Wait a few seconds to check whether anything terminated early
    time.sleep(3)
    return utils.response(**make_status_response(info_item))


@router.put("/advance-queue", tags=["Process Corpus"], response_model=models.BaseResponse, include_in_schema=False)
async def advance_queue(
    secret_key: str = Query(..., alias="secret_key", description="Secret key for authentication"),
) -> JSONResponse:
    """Check the job queue and attempt to advance it.

    1. Unqueue jobs that are done, aborted or erroneous
    2. For running jobs, check if process is still running
    3. Run the next job in the queue if there are fewer running jobs than allowed

    For Mink internal use only!
    """
    if secret_key != settings.MINK_SECRET_KEY:
        raise exceptions.MinkHTTPException(
            status.HTTP_401_UNAUTHORIZED,
            message="Failed to confirm secret key for protected route",
            return_code="failed_confirming_secret_key",
        )

    # Unqueue jobs that are done, aborted or erroneous
    registry.unqueue_inactive()

    # For running jobs, check if process is still running
    running_jobs, waiting_jobs = registry.get_running_waiting()
    logger.debug("Running jobs: %d  Waiting jobs: %d", len(running_jobs), len(waiting_jobs))
    for job in running_jobs:
        try:
            if not job.process_running():
                try:
                    job.abort_sparv()
                except exceptions.ProcessNotRunningError:
                    pass
                registry.pop_from_queue(job)
        except Exception:  # noqa: PERF203
            logger.exception("Failed to check if process is running for '%s'", job.id)

    # Get running jobs again in case jobs were unqueued in the previous step
    running_jobs, waiting_jobs = registry.get_running_waiting()
    # If there are fewer running jobs than allowed, start the next one in the queue
    while waiting_jobs and len(running_jobs) < settings.SPARV_WORKERS:
        job = waiting_jobs.pop(0)
        try:
            if job.status.is_waiting():
                if job.current_process == ProcessName.sparv.name:
                    job.run_sparv()
                    logger.info("Started annotation process for '%s'", job.id)
                elif job.current_process == ProcessName.korp.name:
                    job.install_korp()
                    logger.info("Started Korp installation process for '%s'", job.id)
                elif job.current_process == ProcessName.strix.name:
                    job.install_strix()
                    logger.info("Started Strix installation process for '%s'", job.id)
            running_jobs.append(job)
        except Exception:
            logger.exception("Failed to run Sparv on '%s'", job.id)

    return utils.response(message="Queue advancing completed", return_code="advanced_queue")


@router.get(
    "/resource-info",
    tags=["Process Corpus"],
    response_model=sparv_models.StatusResponse | sparv_models.StatusesResponse,
    responses={
        **models.common_auth_error_responses,
        status.HTTP_404_NOT_FOUND: {
            "model": models.ErrorResponse404,
            "content": {
                "application/json": {
                    "example": {
                        "status": "error",
                        "message": "Corpus 'mink-dxh6e6wtff' does not exist or you do not have access to it",
                        "return_code": "corpus_not_found",
                    }
                }
            },
        },
        status.HTTP_500_INTERNAL_SERVER_ERROR: {
            "model": models.ErrorResponse500,
            "content": {
                "application/json": {
                    "example": {
                        "status": "error",
                        "message": "Failed to get job status for 'mink-dxh6e6wtff'",
                        "return_code": "failed_getting_job_status",
                        "info": "BaseException",
                    }
                }
            },
        },
    },
)
async def resource_info(
    # Parameter is defined again here to allow for None (since it is optional in this route)
    resource_id: str | None = Query(None, description="Resource ID"),
    auth_data: dict = Depends(login.AuthDependency(require_resource_id=False)),
) -> JSONResponse:
    """Return the status of the current job for a corpus or all corpora belonging to the user.

    If the resource ID is provided, the status of the specific resource is returned. Otherwise, the statuses of all
    resources are returned.

    If admin mode is turned on, the owner information is included for each resource.

    ### Example

    ```bash
    curl -X GET '{{host}}/resource-info?resource_id=some_resource_id' -H 'Authorization: Bearer YOUR_JWT'
    ```
    """
    resource_id = auth_data.get("resource_id")
    corpora = auth_data.get("resources", [])

    admin_status = cache_utils.get_cookie_data(auth_data.get("session_id"), {}).get("admin_mode", False)
    if resource_id:
        # Check if corpus exists
        if resource_id not in corpora:
            raise exceptions.MinkHTTPException(
                status.HTTP_404_NOT_FOUND,
                message=f"Corpus '{resource_id}' does not exist or you do not have access to it",
                return_code="corpus_not_found",
            )
        try:
            info = registry.get(resource_id)
        except Exception as e:
            raise exceptions.MinkHTTPException(
                status.HTTP_500_INTERNAL_SERVER_ERROR,
                message=f"Failed to get job status for '{resource_id}'",
                return_code="failed_getting_job_status",
                info=str(e),
            ) from e
        if not info:
            return utils.response(
                message=f"There is no active job for '{resource_id}'",
                return_code="no_active_job",
                job_status=JobStatuses().serialize(),
            )
        return utils.response(**make_status_response(info, admin=admin_status))

    try:
        # Get all job statuses for this user's corpora
        res_list = []
        resources = registry.filter_resources(corpora)
        for res in resources:
            resp_dict = make_status_response(res, admin=admin_status)
            res_list.append(resp_dict)
        return utils.response(message="Listing resource infos", resources=res_list, return_code="listing_jobs")
    except Exception as e:
        raise exceptions.MinkHTTPException(
            status.HTTP_500_INTERNAL_SERVER_ERROR,
            message="Failed to get job statuses",
            return_code="failed_getting_job_statuses",
            info=str(e),
        ) from e


@router.post(
    "/abort-job",
    tags=["Process Corpus"],
    response_model=models.BaseResponse,
    responses={
        status.HTTP_200_OK: {
            "content": {
                "application/json": {
                    "example": {
                        "status": "success",
                        "message": "Successfully aborted job for 'mink-dxh6e6wtff'",
                        "return_code": "aborted_job",
                    }
                }
            }
        },
        **models.common_auth_error_responses,
        status.HTTP_404_NOT_FOUND: {
            "model": models.ErrorResponse404,
            "content": {
                "application/json": {
                    "example": {
                        "status": "error",
                        "message": "No running job found for 'mink-dxh6e6wtff'",
                        "return_code": "no_running_job",
                    }
                }
            },
        },
        status.HTTP_500_INTERNAL_SERVER_ERROR: {
            "model": models.ErrorResponse500,
            "content": {
                "application/json": {
                    "example": {
                        "status": "error",
                        "message": "Failed to abort job for 'mink-dxh6e6wtff'",
                        "return_code": "failed_aborting_job",
                        "info": "BaseException",
                    }
                }
            },
        },
        status.HTTP_503_SERVICE_UNAVAILABLE: {
            "model": models.BaseErrorResponse,
            "content": {
                "application/json": {
                    "example": {
                        "status": "error",
                        "message": "Cannot abort job while syncing files",
                        "return_code": "failed_aborting_job_syncing",
                    }
                }
            },
        },
    },
)
async def abort_job(auth_data: dict = Depends(login.AuthDependency())) -> JSONResponse:
    """Abort the currently running job for the corpus.

    If the job is in the queue but not yet running, it will be removed from the queue. If the job is running, it will be
    stopped.

    ### Example

    ```bash
    curl -X POST '{{host}}/abort-job?resource_id=some_resource_id' -H 'Authorization: Bearer YOUR_JWT'
    ```
    """
    resource_id = auth_data["resource_id"]
    job = registry.get(resource_id).job
    # Syncing
    if job.status.is_syncing():
        raise exceptions.MinkHTTPException(
            status.HTTP_503_SERVICE_UNAVAILABLE,
            message="Cannot abort job while syncing files",
            return_code="failed_aborting_job_syncing",
        )
    # Waiting
    if job.status.is_waiting():
        try:
            registry.pop_from_queue(job)
            job.set_status(Status.aborted)
            return utils.response(
                message=f"Successfully aborted job for '{resource_id}'",
                return_code="aborted_job",
                job_status=job.status.serialize(),
            )
        except Exception as e:
            raise exceptions.MinkHTTPException(
                status.HTTP_500_INTERNAL_SERVER_ERROR,
                message=f"Failed to unqueue job for '{resource_id}'",
                return_code="failed_unqueuing_job",
                info=str(e),
            ) from e
    # No running job
    if not job.status.is_running():
        raise exceptions.MinkHTTPException(
            status.HTTP_404_NOT_FOUND,
            message=f"No running job found for '{resource_id}'",
            return_code="no_running_job",
        )
    # Running job, try to abort
    try:
        job.abort_sparv()
    except exceptions.ProcessNotRunningError as e:
        raise exceptions.MinkHTTPException(
            status.HTTP_404_NOT_FOUND,
            message=f"No running job found for '{resource_id}'",
            return_code="no_running_job",
        ) from e
    except Exception as e:
        raise exceptions.MinkHTTPException(
            status.HTTP_500_INTERNAL_SERVER_ERROR,
            message=f"Failed to abort job for '{resource_id}'",
            return_code="failed_aborting_job",
            info=str(e),
        ) from e
    return utils.response(
        message=f"Successfully aborted job for '{resource_id}'",
        return_code="aborted_job",
        job_status=job.status.serialize(),
    )


@router.delete(
    "/clear-annotations",
    tags=["Process Corpus"],
    response_model=models.BaseResponse,
    responses={
        status.HTTP_200_OK: {
            "content": {
                "application/json": {
                    "example": {
                        "status": "success",
                        "message": "Annotations for 'mink-dxh6e6wtff' successfully removed",
                        "return_code": "removed_annotations",
                    }
                }
            }
        },
        **models.common_auth_error_responses,
        status.HTTP_500_INTERNAL_SERVER_ERROR: {
            "model": models.ErrorResponse500,
            "content": {
                "application/json": {
                    "example": {
                        "status": "error",
                        "message": "Failed to clear annotations",
                        "return_code": "failed_clearing_annotations",
                        "info": "BaseException",
                    }
                }
            },
        },
        status.HTTP_503_SERVICE_UNAVAILABLE: {
            "model": models.BaseErrorResponse,
            "content": {
                "application/json": {
                    "example": {
                        "status": "error",
                        "message": "Cannot clear annotations while a job is running",
                        "return_code": "failed_clearing_annotations_job_running",
                    }
                }
            },
        },
    },
)
async def clear_annotations(auth_data: dict = Depends(login.AuthDependency())) -> JSONResponse:
    """Remove all annotation files for the corpus from the Sparv server.

    This action cannot be performed while a job is running.

    ### Example

    ```bash
    curl -X DELETE '{{host}}/clear-annotations?resource_id=some_resource_id' -H 'Authorization: Bearer YOUR_JWT'
    ```
    """
    resource_id = auth_data["resource_id"]
    # Check if there is an active job
    job = registry.get(resource_id).job
    if job.status.is_running():
        raise exceptions.MinkHTTPException(
            status.HTTP_503_SERVICE_UNAVAILABLE,
            message="Cannot clear annotations while a job is running",
            return_code="failed_clearing_annotations_job_running",
        )

    try:
        sparv_output = job.clean()
        return utils.response(
            message=f"Annotations for '{resource_id}' successfully removed",
            return_code="removed_annotations",
            sparv_output=sparv_output,
        )
    except Exception as e:
        raise exceptions.MinkHTTPException(
            status.HTTP_500_INTERNAL_SERVER_ERROR,
            message="Failed to clear annotations",
            return_code="failed_clearing_annotations",
            info=str(e),
        ) from e


@router.put(
    "/install-korp",
    tags=["Process Corpus"],
    response_model=sparv_models.StatusResponse,
    responses={
        **models.common_auth_error_responses,
        status.HTTP_500_INTERNAL_SERVER_ERROR: {
            "model": models.ErrorResponse500,
            "content": {
                "application/json": {
                    "example": {
                        "status": "error",
                        "message": "Failed to queue job for 'mink-dxh6e6wtff'",
                        "return_code": "failed_queuing",
                        "info": "BaseException",
                    }
                }
            },
        },
    },
)
async def install_korp(
    scramble: bool = Query(False, description="Indicates whether the corpus should be scrambled in Korp"),
    auth_data: dict = Depends(login.AuthDependency()),
) -> JSONResponse:
    """Install the corpus in Korp with Sparv.

    The `scramble` parameter can be used to scramble the corpus data before installation.

    ### Example

    ```bash
    curl -X PUT '{{host}}/install-korp?resource_id=some_resource_id?scramble=true' -H 'Authorization: Bearer YOUR_JWT'
    ```
    """
    resource_id = auth_data["resource_id"]

    # Get info_item, check for changes and remove exports if necessary
    sources_deleted = config_changed = False
    try:
        info_item = registry.get(resource_id)
        _, sources_deleted, config_changed = storage.get_file_changes(resource_id, info_item)
    except exceptions.JobNotFoundError:
        pass
    except Exception as e:
        raise exceptions.MinkHTTPException(
            status.HTTP_500_INTERNAL_SERVER_ERROR,
            message=f"Failed to run job for '{resource_id}'",
            return_code="failed_running",
            info=str(e),
        ) from e
    if sources_deleted or config_changed:
        try:
            success, sparv_output = info_item.job.clean_export()
            assert success
        except Exception as e:
            raise exceptions.MinkHTTPException(
                status.HTTP_500_INTERNAL_SERVER_ERROR,
                message=f"Failed to remove export files from Sparv server for corpus '{resource_id}'. "
                "Cannot run Sparv safely",
                return_code="failed_removing_exports",
                info=str(e),
                sparv_message=sparv_output,
            ) from e

    # Queue job
    job = info_item.job
    job.set_install_scrambled(scramble)
    try:
        job = registry.add_to_queue(job)
    except Exception as e:
        raise exceptions.MinkHTTPException(
            status.HTTP_500_INTERNAL_SERVER_ERROR,
            message=f"Failed to queue job for '{resource_id}'",
            return_code="failed_queuing",
            info=str(e),
        ) from e

    job.set_status(Status.waiting, ProcessName.korp)

    # Wait a few seconds to check whether anything terminated early
    time.sleep(3)
    return utils.response(**make_status_response(info_item))


@router.delete(
    "/uninstall-korp",
    tags=["Process Corpus"],
    response_model=models.BaseResponse,
    responses={
        status.HTTP_200_OK: {
            "content": {
                "application/json": {
                    "example": {
                        "status": "success",
                        "message": "Corpus 'mink-dxh6e6wtff' successfully removed from Korp",
                        "return_code": "uninstalled_korp",
                    }
                }
            }
        },
        **models.common_auth_error_responses,
        status.HTTP_503_SERVICE_UNAVAILABLE: {
            "model": models.BaseErrorResponse,
            "content": {
                "application/json": {
                    "example": {
                        "status": "error",
                        "message": "Cannot uninstall while a job is running",
                        "return_code": "failed_uninstalling_job_running",
                    }
                }
            },
        },
        status.HTTP_500_INTERNAL_SERVER_ERROR: {
            "model": models.ErrorResponse500,
            "content": {
                "application/json": {
                    "example": {
                        "status": "error",
                        "message": "Failed to uninstall corpus from Korp",
                        "return_code": "failed_uninstalling_korp",
                        "info": "BaseException",
                    }
                }
            },
        },
    },
)
async def uninstall_korp(auth_data: dict = Depends(login.AuthDependency())) -> JSONResponse:
    """Uninstall the corpus from Korp with Sparv.

    ### Example

    ```bash
    curl -X DELETE '{{host}}/uninstall-korp?resource_id=some_resource_id' -H 'Authorization: Bearer YOUR_JWT'
    ```
    """
    resource_id = auth_data["resource_id"]
    # Check if there is an active job
    job = registry.get(resource_id).job
    if job.status.is_running():
        raise exceptions.MinkHTTPException(
            status.HTTP_503_SERVICE_UNAVAILABLE,
            message="Cannot uninstall while a job is running",
            return_code="failed_uninstalling_job_running",
        )

    try:
        sparv_output = job.uninstall_korp()
        return utils.response(
            message=f"Corpus '{resource_id}' successfully removed from Korp",
            return_code="uninstalled_korp",
            sparv_output=sparv_output,
        )
    except Exception as e:
        raise exceptions.MinkHTTPException(
            status.HTTP_500_INTERNAL_SERVER_ERROR,
            message="Failed to uninstall corpus from Korp",
            return_code="failed_uninstalling_korp",
            info=str(e),
        ) from e


@router.put(
    "/install-strix",
    tags=["Process Corpus"],
    response_model=sparv_models.StatusResponse,
    responses={
        **models.common_auth_error_responses,
        status.HTTP_500_INTERNAL_SERVER_ERROR: {
            "model": models.ErrorResponse500,
            "content": {
                "application/json": {
                    "example": {
                        "status": "error",
                        "message": "Failed to queue job for 'mink-dxh6e6wtff'",
                        "return_code": "failed_queuing",
                        "info": "BaseException",
                    }
                }
            },
        },
    },
)
async def install_strix(auth_data: dict = Depends(login.AuthDependency())) -> JSONResponse:
    """Install the corpus in Strix with Sparv.

    ### Example

    ```bash
    curl -X PUT '{{host}}/install-strix?resource_id=some_resource_id' -H 'Authorization: Bearer YOUR_JWT'
    ```
    """
    resource_id = auth_data["resource_id"]

    # Get info_item, check for changes and remove exports if necessary
    sources_deleted = config_changed = False
    try:
        info_item = registry.get(resource_id)
        _, sources_deleted, config_changed = storage.get_file_changes(resource_id, info_item)
    except exceptions.JobNotFoundError:
        pass
    except Exception as e:
        raise exceptions.MinkHTTPException(
            status.HTTP_500_INTERNAL_SERVER_ERROR,
            message=f"Failed to run job for '{resource_id}'",
            return_code="failed_running",
            info=str(e),
        ) from e
    if sources_deleted or config_changed:
        try:
            success, sparv_output = info_item.job.clean_export()
            assert success
        except Exception as e:
            raise exceptions.MinkHTTPException(
                status.HTTP_500_INTERNAL_SERVER_ERROR,
                message=f"Failed to remove export files from Sparv server for corpus '{resource_id}'. "
                "Cannot run Sparv safely",
                return_code="failed_removing_exports",
                info=str(e),
                sparv_message=sparv_output,
            ) from e

    # Queue job
    job = info_item.job
    try:
        job = registry.add_to_queue(job)
    except Exception as e:
        raise exceptions.MinkHTTPException(
            status.HTTP_500_INTERNAL_SERVER_ERROR,
            message=f"Failed to queue job for '{resource_id}'",
            return_code="failed_queuing",
            info=str(e),
        ) from e

    job.set_status(Status.waiting, ProcessName.strix)

    # Wait a few seconds to check whether anything terminated early
    time.sleep(3)
    return utils.response(**make_status_response(info_item))


@router.delete(
    "/uninstall-strix",
    tags=["Process Corpus"],
    response_model=models.BaseResponse,
    responses={
        status.HTTP_200_OK: {
            "content": {
                "application/json": {
                    "example": {
                        "status": "success",
                        "message": "Corpus 'mink-dxh6e6wtff' successfully removed from Strix",
                        "return_code": "uninstalled_strix",
                    }
                }
            }
        },
        **models.common_auth_error_responses,
        status.HTTP_503_SERVICE_UNAVAILABLE: {
            "model": models.BaseErrorResponse,
            "content": {
                "application/json": {
                    "example": {
                        "status": "error",
                        "message": "Cannot uninstall while a job is running",
                        "return_code": "failed_uninstalling_job_running",
                    }
                }
            },
        },
        status.HTTP_500_INTERNAL_SERVER_ERROR: {
            "model": models.ErrorResponse500,
            "content": {
                "application/json": {
                    "example": {
                        "status": "error",
                        "message": "Failed to uninstall corpus from Strix",
                        "return_code": "failed_uninstalling_strix",
                        "info": "BaseException",
                    }
                }
            },
        },
    },
)
async def uninstall_strix(auth_data: dict = Depends(login.AuthDependency())) -> JSONResponse:
    """Uninstall the corpus from Strix with Sparv.

    ### Example

    ```bash
    curl -X DELETE '{{host}}/uninstall-strix?resource_id=some_resource_id' -H 'Authorization: Bearer YOUR_JWT'
    ```
    """
    resource_id = auth_data["resource_id"]
    # Check if there is an active job
    job = registry.get(resource_id).job
    if job.status.is_running():
        raise exceptions.MinkHTTPException(
            status.HTTP_503_SERVICE_UNAVAILABLE,
            message="Cannot uninstall while a job is running",
            return_code="failed_uninstalling_job_running",
        )

    try:
        sparv_output = job.uninstall_strix()
        return utils.response(
            message=f"Corpus '{resource_id}' successfully removed from Strix",
            return_code="uninstalled_strix",
            sparv_output=sparv_output,
        )
    except Exception as e:
        raise exceptions.MinkHTTPException(
            status.HTTP_500_INTERNAL_SERVER_ERROR,
            message="Failed to uninstall corpus from Strix",
            return_code="failed_uninstalling_strix",
            info=str(e),
        ) from e


def make_status_response(info: info.Info, admin: bool = False) -> dict:
    """Check the annotation status for a given corpus and return a dict that can be used to make a response.

    Args:
        info: The info object.
        admin: Whether the user is an admin.
    """
    info.job.update_job_info()
    info_attrs = info.to_dict()

    if not admin:
        # Only show owner info in admin mode
        info_attrs.pop("owner", None)

    job_status = info.job.status

    if job_status.is_none():
        return {"message": f"There is no active job for '{info.job.id}'", "return_code": "no_active_job", **info_attrs}

    if job_status.is_syncing():
        return {"message": "Files are being synced", "return_code": "syncing_files", **info_attrs}

    if job_status.is_waiting():
        return {"message": "Job has been queued", "return_code": "job_queued", **info_attrs}

    if job_status.is_aborted(info.job.current_process):
        return {"message": "Job was aborted by the user", "return_code": "job_aborted_by_user", **info_attrs}

    if job_status.is_running():
        return {"message": "Job is running", "return_code": "job_running", **info_attrs}

    # If done annotating, sync exports from Sparv to storage server (don't do this in admin mode)
    if job_status.is_done(ProcessName.sparv) and not storage.local and not admin:
        try:
            info.job.sync_results()
        except Exception as e:
            return {
                "message": "Sparv was run successfully but exports failed to upload to the storage server",
                "return_code": "sparv_success_export_upload_fail",
                "info": str(e),
            }
        return {
            "message": "Sparv was run successfully. Starting to sync results",
            "return_code": "sparv_success_start_sync",
            **info_attrs,
        }

    if job_status.is_done(info.job.current_process):
        return {"message": "Job was completed successfully", "return_code": "job_completed", **info_attrs}

    if job_status.is_error(info.job.current_process):
        logger.error(
            "An error occurred during processing, warnings: %s, errors: %s, sparv_output: %s, job_attrs: %s",
            info_attrs["job"]["warnings"],
            info_attrs["job"]["errors"],
            info_attrs["job"]["sparv_output"],
            info_attrs,
        )
        return {"message": "An error occurred during processing", "return_code": "processing_error", **info_attrs}

    raise exceptions.MinkHTTPException(
        status.HTTP_501_NOT_IMPLEMENTED,
        message="Cannot handle this Job status yet",
        return_code="cannot_handle_status",
        **info_attrs,
    )


@router.get(
    "/sparv-languages",
    tags=["Documentation"],
    response_model=sparv_models.LanguagesResponse,
    responses={
        status.HTTP_500_INTERNAL_SERVER_ERROR: {
            "model": models.ErrorResponse500,
            "content": {
                "application/json": {
                    "example": {
                        "status": "error",
                        "message": "Failed listing languages",
                        "return_code": "failed_listing_languages",
                        "info": "BaseException",
                    },
                }
            },
        }
    },
)
async def sparv_languages() -> JSONResponse:
    """List languages available in Sparv along with their language codes (ISO 639-3).

    ### Example

    ```bash
    curl -X GET '{{host}}/sparv-languages'
    ```
    """
    try:
        job = jobs.DefaultJob()
        languages = job.list_languages()
    except Exception as e:
        raise exceptions.MinkHTTPException(
            status.HTTP_500_INTERNAL_SERVER_ERROR,
            message="Failed listing languages",
            return_code="failed_listing_languages",
            info=str(e),
        ) from e
    return utils.response(
        message="Listing languages available in Sparv", return_code="listing_languages", languages=languages
    )


@router.get(
    "/sparv-exports",
    tags=["Documentation"],
    response_model=sparv_models.ExportsResponse,
    responses={
        status.HTTP_422_UNPROCESSABLE_ENTITY: {"model": models.ErrorResponse422},
        status.HTTP_500_INTERNAL_SERVER_ERROR: {
            "model": models.ErrorResponse500,
            "content": {
                "application/json": {
                    "example": {
                        "status": "error",
                        "message": "Failed listing exports",
                        "return_code": "failed_listing_sparv_exports",
                        "info": "BaseException",
                    }
                }
            },
        },
    },
)
async def sparv_exports(
    language: str = Query("swe", description="languages for which to list exports"),
) -> JSONResponse:
    """List available Sparv export formats for the chosen language (default: 'swe').

    The language is specified with the `language` as ISO 639-3 code. See available languages by calling
    <{{host}}/sparv-languages>.

    ### Example

    ```bash
    curl -X GET '{{host}}/sparv-exports?language=swe'
    ```
    """
    try:
        job = jobs.DefaultJob(language=language)
        exports = job.list_exports()
    except Exception as e:
        raise exceptions.MinkHTTPException(
            status.HTTP_500_INTERNAL_SERVER_ERROR,
            message="Failed listing exports",
            return_code="failed_listing_sparv_exports",
            info=str(e),
        ) from e
    return utils.response(
        message="Listing exports available in Sparv",
        return_code="listing_sparv_exports",
        language=language,
        exports=exports,
    )
