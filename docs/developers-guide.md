# Mink Backend – Developer's Guide

Mink is [Språkbanken Text](https://spraakbanken.gu.se/)'s data platform, enabling users to upload corpus data, annotate
it with [Sparv](https://spraakbanken.gu.se/sparv), and view or search it in [Korp](https://spraakbanken.gu.se/korp) and
[Strix](https://spraakbanken.gu.se/strix).

This project is a [FastAPI](https://fastapi.tiangolo.com/) application supporting the [Mink
frontend](https://spraakbanken.gu.se/mink). It provides endpoints for uploading and downloading corpus files, processing
corpora with Sparv, and installing them in Korp and Strix.

This guide is intended for Mink backend developers. It describes the backend's functionality, outlines the application's
structure and key components, and explains how the API is documented and tested.

## Server Setup

The Mink backend can be distributed across several servers, each serving a specific role:

- **Backend server**: Hosts the FastAPI application, handling API requests and coordinating backend operations.
- **Storage server**: Stores users' source files, configuration files, and export files. This server ensures
  persistent storage.
- **Sparv server**: Runs Sparv for annotation and processing tasks. Ideally equipped with a GPU, this server requires
  the corpus source and config files to be synchronized from the storage server before processing. Temporary working
  files are stored here during processing and may be deleted after completion or inactivity. Export files generated by
  Sparv are also stored here and later synchronized back to the storage server. In the current Mink setup, the Sparv
  server also serves as the storage server, so no synchronization is needed.
- **Installation targets**: Installing corpora from Mink involves synchronizing specific Sparv export files to servers
  hosting other applications, such as Korp and Strix.

## Workflow for Mink Users

Users are not required to follow a strict sequence when interacting with the Mink API, but there is a recommended
workflow that helps ensure successful data processing. The following steps outline this typical workflow and provide
an overview of how the Mink backend operates. Rather than describing every available API route, they focus on the main
steps a user would typically take when working with Mink.

### Creating a New Corpus

Before any data can be uploaded or processed, a user must create a corpus. (When using the Mink frontend, this step is
handled automatically.) Creating a new corpus generates a unique corpus ID (prefixed with `mink-`) and an [info
object](#info-object). The corpus ID is registered in the authentication system, and the user who creates the corpus is
assigned owner rights. To create a new corpus, use the `/create-corpus` route.

### Uploading Corpus Source Files

When you upload corpus source files, they are stored on the [storage server](#server-setup) in a directory named after
the corpus ID. If you upload multiple files, Mink checks that all file extensions match, as Sparv requires source files
to be of the same type. Use the `/upload-sources` route to upload your source files.

### Uploading a Corpus Config File

Before a corpus can be processed with Sparv, the user must upload a [Sparv corpus config
file](https://spraakbanken.gu.se/sparv/user-manual/corpus-configuration/). When using Mink through the frontend, this
step is usually handled automatically, as the frontend generates a default config file. When a config file is uploaded,
Mink checks that the `importer` specified in the config matches the file extension of any previously uploaded source
files (if present). To upload a config file, use the `/upload-config` route.

### Running Sparv

When a corpus has both source files and a valid corpus config file, it can be processed with Sparv. This process
enriches the source files with automatic annotations and generates various output formats (exports). To start
processing, use the `/run-sparv` route. If the [storage server](#server-setup) and [Sparv server](#server-setup) are
separate, calling `/run-sparv` will first synchronize the source files and the config file from the storage server to
the Sparv server; otherwise, this step is skipped. Before running Sparv, Mink verifies that the `importer` specified in
the config file matches the file extension of the source files (in case the config was uploaded first).

The Sparv job is then added to the [job queue](#job-queue). Once all previous jobs in the queue have been processed, the
[queue manager](#queue-manager) will automatically run this job, and Sparv will process the corpus.

### Checking the Status

When a job has been queued, its status can be checked using the `/resource-info` route. The response includes details
such as the queue priority, the status of the annotation process, processing duration, and any warnings or errors
generated by Sparv. For an explanation of the different status codes, refer to the `status_codes` section in the
response from the `/info` route.

In setups where the [storage server](#server-setup) and [Sparv server](#server-setup) are separate, it is necessary to
call `/resource-info` after the annotation process completes to ensure export files are synchronized.

### Downloading Export Files

After a Sparv job completes, users can download the resulting export files for further analysis or use. This is done via
the `/download-exports` route. Users may choose to download all available exports, or select specific subdirectories or
files as needed.

### Installing in Korp and/or Strix

In addition to downloading export files, users may want to install their corpus in the corpus search tools Korp or Strix
(or both). This is accomplished using the `/install-korp` and `/install-strix` routes. Installation is performed by
Sparv, and the installation job is added to the job queue in the same way as annotation jobs.

After a successful installation, users can log in to Korp or Strix and search their own corpora as usual. Installations
are private, meaning only the logged-in user who owns the installed corpus can view it.

### Other Resource Types

Currently, the Mink backend is primarily designed for processing and installing corpora. However, support for a new
resource type, "metadata," has recently been introduced. A metadata resource consists of a YAML file containing
descriptive information about a corpus, lexicon, analysis, or collection. These metadata files are used to generate
[Språkbanken Text's resources page](https://spraakbanken.gu.se/en/resources). For more details about the structure and
usage of metadata YAML files, see the [metadata repository](https://github.com/spraakbanken/metadata).

You can create a metadata resource using the `/create-metadata` route and remove it with the `/remove-metadata` route.
The metadata file itself is uploaded via the `/upload-metadata` route and can be downloaded using the
`/download-metadata` route.

Additional features for metadata resources are planned, and support for other resource types may be added in the future.

## Authentication and Authorization

Mink relies on [SB Auth](https://github.com/spraakbanken/sb-auth), a Django-based authentication and authorization
service developed by Språkbanken Text, to secure access to resources.

### Authentication

All requests to the Mink backend that interact with resources must be authenticated. Mink supports two authentication
mechanisms:

- **JSON Web Token (JWT):** Issued by SB Auth after successful Shibboleth login.
- **API key:** Provided by SB Auth for programmatic access.

To authenticate, include either a valid JWT or API key in the request headers. For exact details on how to obtain and
use these credentials, refer to the `/redoc#section/Authentication` documentation.

User identity is determined and verified via Shibboleth, which is integrated with SB Auth. This ensures that only users
who have authenticated through their institution's identity provider (via the academic identity federation) can access
protected endpoints.

### Authorization

After authentication, Mink enforces fine-grained authorization using SB Auth. When a new resource is created, it is
registered with SB Auth, and ownership is assigned to the user who created it. By default:

- **Only the resource owner** can view, modify, or delete their resources.
- **Resource sharing** is not currently supported via the API.
- **SB Auth administrators** (Språkbanken staff) can manually add collaborators to resources upon request if special
  access is needed.

For any operation involving resources, Mink consults SB Auth to verify that the authenticated user has the required
permissions for the requested action.

## Key Concepts

The following sections describe some important concepts and components of the Mink backend. These concepts are essential
for understanding how Mink operates and how different parts of the application interact with each other.

### Configuration

The default configuration for the Mink backend is defined in the `Settings` class within `mink/core/config.py`. You can
override these defaults by creating a `.env` file in the project's root directory. The `.env` file should use standard
environment variable formatting, with each line specifying a key-value pair. For example:

```ini
LOG_LEVEL=DEBUG
LOG_TO_FILE=False
MINK_URL=http://localhost:8000
SPARV_IMPORTER_MODULES={".xml":"xml_import", ".txt":"text_import", ".pdf":"pdf_import"}
SPARV_DEFAULT_EXPORTS=["xml_export:pretty", "csv_export:csv", "stats_export:sbx_freq_list"]
```

All configuration variables are available via the `mink.core.config.settings` object:

```python
from mink.core.config import settings

print(settings.MINK_URL)  # Output: http://localhost:8000
```

### Instance Directory

The instance directory is located at the root of the project and contains all files specific to a given backend
instance. Its contents include:

- `logs/`: Contains log files generated by the application.
- `registry/`: Stores the resource registry.
- `tmp/`: Temporary storage for files downloaded by users.
- `pubkey.pem`: Public key used for verifying JWT tokens.
- `queue`: Maintains the job queue.

### Resource ID

A resource ID uniquely identifies each resource in the Mink backend instance. When a new resource is created, an ID is
generated, which is prefixed with the value specified in the `RESOURCE_PREFIX` configuration variable (default:
`mink-`). This ID is used to reference the resource in API calls and is essential for tracking its lifecycle. The
resource ID is also registered with the authentication system, enabling Mink to manage user permissions and access
control for the resource.

### Info Object

An info object is generated whenever a new resource is created. It is composed of three sub-objects:

- `resource`: Contains general properties of the resource, such as its [resource ID](#resource-id), names in different
  languages, resource type, and the list of available source files.
- `owner`: Provides information about the user who created the resource, including user ID, name, and email address.
- `job`: Provides details about the most recent Sparv job for the resource, including job status, annotation progress,
  and queue priority.

The info object is saved as a JSON file in the instance directory and is also cached using
[Memcached](https://memcached.org/) for faster access. It is updated whenever a Sparv process is run, when file
operations occur (such as uploading a new source file), or when `/resource-info` is called.

### Job Queue

To prevent the Sparv server from being overloaded by too many simultaneous annotation or installation processes, the
Mink backend uses a job queue system. When a user requests to process or install a corpus, a job is added to the queue.
The [queue manager](#queue-manager), which runs as a separate process, regularly checks whether there is available
capacity — determined by the `SPARV_WORKERS` configuration variable, which specifies how many Sparv jobs can run
concurrently. If capacity is available, the annotation or installation process for the next job in the queue is started.
The queue manager communicates with the Mink API by calling the `/advance-queue` route.

The job queue consists of a list of queued resource IDs. It is stored as plain text in the instance directory and is
also cached using [Memcached](https://memcached.org/) for fast access.

### Queue Manager

The queue manager runs as an independent process, separate from the FastAPI application. It is scheduled to execute at
regular intervals using the [APScheduler](https://apscheduler.readthedocs.io/en/3.x/) Python package. The queue manager
communicates with the Mink API by calling the `/advance-queue` API route, which performs the following tasks:

1. Removes jobs from the queue that have finished, been aborted, or encountered errors.
2. Checks running jobs to ensure their processes are still active; if not, those jobs are removed from the queue.
3. If the number of running jobs is below the configured limit (set by the `SPARV_WORKERS` variable), starts the next
   job in the queue.

### Resource Registry

The resource registry keeps track of all resources managed by Mink. It acts as a dictionary, mapping each resource ID to
its corresponding [info object](#info-object).

At application startup, all info objects are loaded from their JSON files and cached for fast access. The job queue is
also read from the instance directory and cached. This approach enables Mink to efficiently manage resources and queue
positions.

A resource remains in the registry from creation until it is deleted.

## Project Structure

The Mink backend is built to be modular and extensible, supporting seamless integration with other components and
services. Developers should strive to keep the codebase modular and reusable, making it easy to swap out individual
components for alternative implementations as needed.

The `main.py` file is the entry point for the FastAPI application. It initializes the app, configures middleware,
registers API routes, and customizes the OpenAPI specification. The application is organized into several packages to
promote modularity and maintainability.

The `core` package provides essential functionality required for normal operation and is not intended to be replaced. It
includes the following modules:

- `config.py`: Defines default Mink backend settings.
- `exceptions.py`: Contains Mink-specific exceptions.
- `info.py`: Handles creation and management of resource info objects.
- `jobs.py`: Manages and executes corpus jobs (processing and installation).
- `logging.py`: Sets up and configures logging.
- `models.py`: Defines Pydantic models for API requests and responses.
- `registry.py`: Manages the resource registry and job queue.
- `resource.py`: Provides classes for resource object creation and handling.
- `routes.py`: Implements general routes independent of non-core functionality (e.g., documentation serving).
- `status.py`: Handles job status management.
- `user.py`: Manages user properties.
- `utils.py`: Contains general utility functions.

Non-core packages offer additional, more easily replaceable functionality:

- `cache`: Implements caching with [Memcached](https://memcached.org/).
- `metadata`: Manages metadata files (a new resource type in Mink).
- `sb_auth`: Handles authentication with SB Auth.
- `sparv`: Manages processing jobs with Sparv and file storage.

## API Documentation

The API for this application is documented using the [OpenAPI Specification](https://spec.openapis.org/oas/v3.1.0)
(OAS), a standard for describing HTTP APIs. The OAS is leveraged to automatically generate documentation web pages,
which are accessible at the `/redoc` and `/swagger` routes. You can also download the specification in JSON format from
the `/openapi.json` route.

Beginning with version 2.0.0, the OAS is generated automatically by FastAPI. To keep the documentation accurate and up
to date, ensure that the docstrings for route functions are maintained. These docstrings typically include bash examples
demonstrating how to call the routes using cURL. The structure of request and response data is defined using Pydantic
models. General information about the API, such as title, description, server URLs, and tag definitions, is specified in
the `openapi_info.yaml` file in the `mink` directory.

## Testing

Automated tests are provided to exercise the Mink backend's API routes and validate a complete resource lifecycle. These
tests use `pytest`. Ensure all required dependencies are installed (for example, by running `pip install -r
requirements-dev.txt`), then execute:

```bash
pytest [--custom-log-level=<log_level>] [--mink-log-level=<log_level>] [-k <test_name>]
```

Manual testing is supported via SwaggerUI, which is bundled with FastAPI and available at `/swagger`. SwaggerUI displays
all documented routes and offers "Try it out" buttons for sending requests directly to the Mink API. When running a
local development server on port 8000, access SwaggerUI at <http://localhost:8000/swagger>.

For convenience, you can add your SB Auth API key to the `SBAUTH_PERSONAL_API_KEY` configuration variable to enable
automatic authentication for each request. You may also set `DEFAULT_RESOURCE_ID` to one of your Mink resource IDs to
pre-fill the `resource-id` parameter in relevant routes. Note that you must set `ENV=development` or `ENV=testing` in
your `.env` configuration file for these features to work.

Additionally, you can download the OpenAPI Specification from the `/openapi.json` route and import it into tools such as
[Apidog](https://apidog.com/) or [Postman](https://www.postman.com/). When using these tools, you may need to configure
environment variables like `host` (e.g., `http://localhost:8000`) and set up authentication (using either JWT or API
key).

## Release

The script `release.sh` in the project root directory automates the release process. For more information, see the
comments in the script itself and run `./release.sh -h`.

When creating a major release, please follow the [todo for major
release](https://github.com/spraakbanken/dev-docs/blob/main/projektinformation/Mink.md#todo-for-major-release) (only
available internally at Språkbanken).
